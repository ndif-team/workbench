remote = true

[models]

[models.one]
name = "openai-community/gpt2"
chat = false

[models.one.rename]
transformer = "model"
h = "layers"
c_proj = "o_proj"

[models.one.config]
n_heads = 12
n_layers = 12

[models.two]
name = "EleutherAI/gpt-j-6b"
chat = false

[models.two.rename]
transformer = "model"
h = "layers"
out_proj = "o_proj"

[models.two.config]
n_heads = 16
n_layers = 28

[models.three]
name = "meta-llama/Meta-Llama-3.1-8B"
chat = false

[models.three.rename]
norm = "ln_f"
self_attn = "attn"

[models.three.config]
n_heads = 32
n_layers = 32

[models.four]
name = "meta-llama/Meta-Llama-3.1-70B"
chat = false

[models.four.rename]
norm = "ln_f"
self_attn = "attn"

[models.four.config]
n_heads = 64
n_layers = 80


# [models.four]
# name = "openai-community/gpt2"
# chat = false

# [models.four.rename]
# transformer = "model"
# h = "layers"
# out_proj = "o_proj"

# [models.four.config]
# n_heads = 12

# [models.four]
# name = "meta-llama/Meta-Llama-3.1-8B-Instruct"
# chat = true

# [models.four.rename]
# norm = "ln_f"

# [models.five]
# name = "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
# chat = false

# [models.five.rename]
# norm = "ln_f"

# [models.six]
# name = "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
# chat = false

# [models.six.rename]
# norm = "ln_f"